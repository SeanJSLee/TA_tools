{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single course with multiple iClicker sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Optional - Excused miss excel worksheet\n",
    "    In my course, we have excused miss sheet which can track students' missed class in each class day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def excused_miss_sheet(path=str, class_day=list, class_begin=str, class_end=str):\n",
    "    # path includes excel file name and extension: \"PATH/FNAME.xlsx\"\n",
    "    # class begin or end format: \"YYYY-MM-DD\"\n",
    "    df = pd.DataFrame(pd.date_range(class_begin, class_end, freq='D').to_list(),columns=['date'])\n",
    "    df['weekday'] = df['date'].dt.day_name()\n",
    "    df = df.loc[df['weekday'].isin(class_day)].reset_index(drop=True)\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    df.to_excel(os.path.abspath(path))\n",
    "\n",
    "excused_miss_sheet('excusedmiss.xlsx', ['Monday','Wednesday','Friday'] ,'2023-08-21', '2023-12-15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Loading Canvas gradebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# \n",
    "# Loading the latest canvas gradebook that saved in a \"Gradebook\" directory.\n",
    "f_canvas        = sorted(glob.glob('Gradebook/*.csv'), key=os.path.getatime, reverse=True)[0]\n",
    "df_canvas       = pd.read_csv(f_canvas, dtype={'ID':str, 'SIS User ID':str}).dropna(subset=['SIS User ID']).sort_values(['Section', 'Student'])\n",
    "# set a short section name for convinience\n",
    "df_canvas['Section_short'] = df_canvas['Section'].str[-1:]\n",
    "\n",
    "\n",
    "# Use following info kept over the program.\n",
    "var_info               = ['Student', 'ID', 'SIS User ID','SIS Login ID','Section']\n",
    "# We use two metrics: Correct answer rate and Participation rate.\n",
    "var_correct_rate       = df_canvas.filter(like='iClicker correct answer rate').columns.values[0]\n",
    "var_participation_rate = df_canvas.filter(like='iClicker participation rate').columns.values[0]\n",
    "\n",
    "# Subsetting only infos for convinience.\n",
    "df_canvas_info = df_canvas[['Student', 'ID', 'SIS User ID','SIS Login ID','Section_short']].rename(columns={'Section_short':'Section'}).reset_index(drop=True).copy()\n",
    "\n",
    "\n",
    "df_canvas_info\n",
    "df_canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Loading class records of iClicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class history file is automatically generated when you downloading class record with my code. \n",
    "# It contains class sequence and its date.\n",
    "df_class_history = {}\n",
    "\n",
    "# \n",
    "for idx, i_hist in enumerate(sorted(glob.glob(r'iClicker\\class_history* sec *.xlsx'), key=os.path.getmtime, reverse=True)[:3][::-1]) :\n",
    "    df_class_history[idx] = pd.read_excel(i_hist).drop(columns=['Unnamed: 0']).sort_values(by=['date']).reset_index(drop=True)\n",
    "    df_class_history[idx]['poll_sec_{0}'.format(idx+1)] = df_class_history[idx]['poll_sec_{0}'.format(idx+1)].str.strip()\n",
    "    \n",
    "# df_class_history[1]\n",
    "\n",
    "\n",
    "\n",
    "# loading the newest iClciker roster of three sections\n",
    "lst_last_3 = sorted(glob.glob(r'iClicker/roster iClicker *.csv'), key=os.path.getmtime, reverse=True)[:3][::-1]\n",
    "print(lst_last_3)\n",
    "\n",
    "# appding 3 sections\n",
    "df_iclicker = pd.DataFrame()\n",
    "for idx, i_file in enumerate(lst_last_3) :\n",
    "    print(idx, i_file, i_file[-5:-4])\n",
    "    # preliminary import\n",
    "    df_i = pd.read_csv(i_file).rename(columns=lambda x: re.sub(' [0-9]+ -','',x))\n",
    "    # get the session info\n",
    "    dtype_info = dict(zip(df_i.filter(like='Class').columns.values, ['int']*len(df_i.filter(like='Class').columns.values)))\n",
    "    df_i = pd.read_csv(i_file, keep_default_na = True, na_values = 'No Response', dtype = dtype_info)\n",
    "    df_i['Section'] = i_file[-5:-4]\n",
    "    #     \n",
    "    # Column name change with class history\n",
    "    df_class_history_i = df_class_history[idx][['date', 'poll_sec_{0}'.format(i_file[-5:-4])]].dropna(how='any')\n",
    "    lst_col_name = dict(zip(df_class_history_i['poll_sec_{0}'.format(i_file[-5:-4])].to_list(), df_class_history_i['date']))\n",
    "    # \n",
    "    df_i = df_i.rename( columns= dict(lst_col_name))\n",
    "    # calculate engage\n",
    "    df_i['engage'] = df_i.filter(like='2023-').count(axis=1)\n",
    "    # summing duplicated dates.\n",
    "    df_i = df_i.groupby(df_i.columns, axis=1).sum()\n",
    "    # \n",
    "    df_iclicker = pd.concat([df_iclicker,df_i], axis=0)\n",
    "\n",
    "df_iclicker\n",
    "df_iclicker['Student'] = df_iclicker['Name']\n",
    "df_iclicker['Current Score'] = df_iclicker['Performance']\n",
    "df_iclicker['Student ID'] = df_iclicker['Student ID'].str.lower().str.strip()\n",
    "\n",
    "# save \"Possible Point\" filter out from students list\n",
    "df_iclicker_max_point = df_iclicker.loc[df_iclicker['Student'] == \"Possible Points\"].reset_index(drop=True)\n",
    "\n",
    "# sorting\n",
    "df_iclicker = df_iclicker.loc[df_iclicker['Student'] != \"Possible Points\"].dropna(subset=['Email']).sort_values(['Section','Student','Student ID']).reset_index(drop=True)\n",
    "\n",
    "# pulling student #\n",
    "df_iclicker['input 0 SIS User ID'] = np.where(df_iclicker['Student ID'].str.match('[0-9]'), df_iclicker['Student ID'], np.NaN)\n",
    "# pulling paw from email\n",
    "df_iclicker['input 1 SIS User Login'] = np.where(df_iclicker['Email'].str.match('[a-z0-9]+@[a-z.]+'), df_iclicker['Email'].str.replace('@[a-z.]+',''), np.NaN)\n",
    "# pulling paw or student # from student input\n",
    "df_iclicker['input 2 SIS User Login'] = np.where(df_iclicker['Student ID'].str.match('[a-z0-9]'), df_iclicker['Student ID'], np.NaN)\n",
    "\n",
    "# merging paw with student #\n",
    "df_iclicker = df_iclicker.merge(df_canvas_info[['SIS User ID','SIS Login ID']].rename(columns={'SIS Login ID':'SIS Login ID 0'}), left_on=['input 0 SIS User ID'], right_on=['SIS User ID'], how='left').drop(columns=['SIS User ID'])\n",
    "# merging paw with from email\n",
    "df_iclicker = df_iclicker.merge(df_canvas_info[['SIS Login ID']].rename(columns={'SIS Login ID':'SIS Login ID 1'}), left_on=['input 1 SIS User Login'], right_on=['SIS Login ID 1'], how='left')\n",
    "# merging paw with student input\n",
    "df_iclicker = df_iclicker.merge(df_canvas_info[['SIS Login ID']].rename(columns={'SIS Login ID':'SIS Login ID 2'}), left_on=['input 2 SIS User Login'], right_on=['SIS Login ID 2'], how='left')\n",
    "\n",
    "# construct paw from mergings.\n",
    "df_iclicker['SIS Login ID'] = np.NaN\n",
    "df_iclicker['SIS Login ID'] = df_iclicker[['SIS Login ID 0', 'SIS Login ID 1', 'SIS Login ID 2','SIS Login ID']].fillna(method='ffill',axis=1)['SIS Login ID']\n",
    "\n",
    "df_iclicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra steps for a student who has multiple accounts\n",
    "\n",
    "# keep the backfilled recored.\n",
    "df_iclicker_paw_fixed_dup = df_iclicker[df_iclicker.duplicated(['SIS Login ID'],False)].sort_values(['SIS Login ID','Current Score'], ascending=False).reset_index(drop=True).groupby(['SIS Login ID']).fillna(method='backfill', axis=0, limit=1).merge(df_iclicker[df_iclicker.duplicated(['SIS Login ID'],False)][['Student', 'SIS Login ID']].drop_duplicates().reset_index(drop=True), how='inner', on='Student').drop_duplicates(['SIS Login ID'],keep='first')\n",
    "df_iclicker_paw_fixed_dup\n",
    "\n",
    "# unpuplicated iclicker\n",
    "df_iclicker_paw_undup = df_iclicker[~df_iclicker.duplicated(['SIS Login ID'],False)].append(df_iclicker_paw_fixed_dup)\n",
    "df_iclicker_paw_undup = df_iclicker_paw_undup.sort_values(['Section', 'Student']).reset_index(drop=True)\n",
    "df_iclicker_paw_undup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Generate grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iclicker_info = df_iclicker_paw_undup[['SIS Login ID', 'Section']]\n",
    "\n",
    "# rebuild Current score\n",
    "df_iclicker_info['Current Score'] = df_iclicker_paw_undup.filter(like='2023-').sum(axis=1)\n",
    "\n",
    "# count response\n",
    "df_iclicker_info['engage'] = df_iclicker_paw_undup['engage']\n",
    "\n",
    "# set max response\n",
    "df_iclicker_max_point['Max engage'] = df_iclicker_max_point.filter(like='2023-').count(axis=1)\n",
    "df_iclicker_info = df_iclicker_info.merge(df_iclicker_max_point[['Current Score','Section', 'Max engage']].rename(columns={'Current Score':'Max Score'}), on='Section')\n",
    "\n",
    "df_iclicker_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Adjust maximum grade with excused misses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading excuses list\n",
    "df_excuses = pd.read_excel('excusedmiss.xlsx', sheet_name = 'Sheet2', usecols='B:ZZ').drop(columns='date').T.reset_index()\n",
    "header = df_excuses.iloc[0]\n",
    "df_excuses.columns = df_excuses.iloc[0]\n",
    "df_excuses = df_excuses[1:].dropna(subset='input paw')\n",
    "df_excuses\n",
    "\n",
    "\n",
    "\n",
    "df_excuses['SIS Login ID'] = df_excuses['SIS Login ID'].str.lower()\n",
    "df_excuses\n",
    "for idx, stu in df_excuses.iterrows():\n",
    "    print(idx, stu[1])\n",
    "    try :\n",
    "        # get section info\n",
    "        # df_iclicker_info\n",
    "        df_stu = df_excuses.loc[df_excuses['SIS Login ID'] == stu[1]].reset_index(drop=True)\n",
    "        df = df_stu.filter(like = '2023-').T\n",
    "        df.index.name = None\n",
    "        lst_cols_for_count = list(df.loc[df[0] != 1].index)\n",
    "        # for max score counting\n",
    "        # set max response\n",
    "        info_section = df_iclicker_info.loc[df_iclicker_info['SIS Login ID'] == stu[1]]['Section'].reset_index(drop=True)[0]\n",
    "        df_tt_max = df_iclicker_max_point.loc[df_iclicker_max_point['Section'] == info_section][df_iclicker_max_point.columns & lst_cols_for_count].reset_index(drop=True)\n",
    "        max_engage = df_tt_max.count(axis=1).min()\n",
    "        # set max score\n",
    "        max_score = df_tt_max.sum(axis=1)[0]\n",
    "        \n",
    "        # for current score counting\n",
    "        df_tt_curr = df_iclicker_paw_undup.loc[df_iclicker_paw_undup['SIS Login ID'] == stu[1]].filter(like='2023-')\n",
    "        # recount current response\n",
    "        current_engage = df_iclicker_paw_undup.loc[df_iclicker_paw_undup['SIS Login ID'] == stu[1]]['engage'].item()\n",
    "        # recount current score\n",
    "        current_score = df_tt_curr[df_tt_curr.columns & lst_cols_for_count].reset_index(drop=True).sum(axis=1)[0]\n",
    "        # \n",
    "        print('found', 'enage_max',max_engage, 'engage', current_engage,'score_max',max_score, 'score',current_score )\n",
    "        df_iclicker_info.loc[df_iclicker_info['SIS Login ID'] == stu[1], 'Max engage'] = max_engage\n",
    "        df_iclicker_info.loc[df_iclicker_info['SIS Login ID'] == stu[1], 'Max Score'] = max_score\n",
    "        df_iclicker_info.loc[df_iclicker_info['SIS Login ID'] == stu[1], 'engage'] = current_engage\n",
    "        df_iclicker_info.loc[df_iclicker_info['SIS Login ID'] == stu[1], 'Current Score'] = current_score\n",
    "    except :\n",
    "        print('fail')\n",
    "        continue\n",
    "    \n",
    "\n",
    "# adding stats\n",
    "df_iclicker_info[var_correct_rate] = round(df_iclicker_info['Current Score'] / df_iclicker_info['Max Score'] * 100)\n",
    "df_iclicker_info[var_correct_rate] = df_iclicker_info[var_correct_rate].apply(lambda x: min(x, 100))\n",
    "df_iclicker_info['iClicker correct response counter'] = df_iclicker_info['Current Score']\n",
    "df_iclicker_info[var_participation_rate] = round(df_iclicker_info['engage'] / df_iclicker_info['Max engage'] * 100)\n",
    "df_iclicker_info[var_participation_rate] = df_iclicker_info[var_participation_rate].apply(lambda x: min(x, 100))\n",
    "# Extra credit - when you need.\n",
    "# df_iclicker_info['Extra credit'] = np.where( df_iclicker_info['iClicker correct answer rate (1439561)'] >= 50, 1,0)\n",
    "df_iclicker_info\n",
    "\n",
    "\n",
    "# Exportable iClicker - bring correct name from canvas \n",
    "df_iclicker_info_exp = df_canvas[['Student', 'ID', 'SIS User ID','SIS Login ID','Section', 'Section_short']].merge(df_iclicker_info.rename(columns={'Section':'Section_short'}), on=['SIS Login ID','Section_short'], how='left').fillna(0)\n",
    "df_iclicker_info_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. Export to Excel and for Canvas import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iclicker_info_exp.to_excel('iClicker/iClicker - gradebook {:%m-%d-%y}.xlsx'.format(datetime.datetime.now()))\n",
    "df_iclicker_info_exp[var_info + [var_correct_rate, var_participation_rate]].to_csv('iClicker/iClicker - canvas import {:%m-%d-%y}.csv'.format(datetime.datetime.now()), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
